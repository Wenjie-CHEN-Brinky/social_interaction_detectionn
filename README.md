
```markdown
# Pedestrian Social Interaction Detection

This repository provides a pipeline for detecting and analyzing pedestrian social interactions in urban spaces using **YOLOv7** for object detection and custom logic to track pedestrians' interactions based on **spatial proximity** and **duration**. The approach identifies social interactions between pedestrians by evaluating their relative distance and how long they remain in proximity.

## Overview

This method uses video footage to automatically detect and analyze pedestrian behaviors. It computes pedestrian trajectories, detects social interactions by considering their relative distance and interaction time, and extracts corresponding video segments to visualize the interactions.

### Key Features:
- **Pedestrian detection** with YOLOv7.
- **Tracking** of individual pedestrians and identification of close proximity interactions.
- **Interaction detection** based on:
  - Distance threshold: **3.7 meters**.
  - Time threshold: **10 seconds**.
- **Output** includes interaction duration, involved IDs, and a video clip highlighting the interaction.

---

## Dependencies

- Python 3.8+
- OpenCV
- NumPy
- argparse
- Additional dependencies:  
  Install required Python packages using the following:
  ```bash
  pip install -r requirements.txt
  ```

---

## Folder Structure

```
project/
â”‚
â”œâ”€â”€ processing/           # Contains video files and tracking data
â”‚   â”œâ”€â”€ runs/             # YOLOv7 outputs and video tracking results
â”‚   â”œâ”€â”€ detect/           # Object detection and tracking results
â”‚   â”œâ”€â”€ labels/           # Parsed tracking data
â”‚   â”œâ”€â”€ object_tracking4/ # Tracking data for individual pedestrians
â”‚
â”œâ”€â”€ utils/                # Utility functions for parsing, tracking, etc.
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # Documentation
```

---

## Data Flow

### 1. Pedestrian Detection (YOLOv7)
The **YOLOv7 model** is used to detect pedestrians from video frames. The model outputs bounding boxes and pedestrian IDs.

### 2. Tracking Pedestrians
Using the **tracking data** (from YOLOv7), the code tracks pedestrian IDs across consecutive frames, reconstructing each pedestrian's trajectory.

### 3. Interaction Identification
- **Close Pairs Detection**: Pedestrians are considered to be interacting if their Euclidean distance is below the defined threshold (**3.7 meters**).
- **Interaction Duration**: Pedestrians' proximity is analyzed over time. If they remain close for **10 seconds or longer**, it is considered a valid interaction.

### 4. Video Extraction
The final video segments highlighting the detected interactions are extracted and saved as separate clips for visual analysis.

---

## Usage

### Step 1: Parse Tracking Data
The first step is to parse the tracking data from the `TXT` files generated by YOLOv7:
```python
data = parse_tracking_data(folder_path)
```

### Step 2: Detect Close Proximity Pairs
Identify pairs of pedestrians that are within the defined distance threshold:
```python
close_pairs = find_close_pairs(data)
```

### Step 3: Track Pairs Across Consecutive Frames
Track the detected pairs over time to identify interactions that last for longer than the threshold:
```python
pair_durations = track_pairs(close_pairs)
```

### Step 4: Filter Long Interactions
Filter pairs that remain in close proximity for at least **10 seconds**:
```python
long_pairs = filter_long_pairs(pair_durations)
```

### Step 5: Extract Videos and Output Details
Extract video clips of the detected interactions and save the details to a `TXT` file:
```python
extract_videos_with_details(video_path, long_pairs, data, close_pairs, output_folder, txt_output_path)
```

---

## Output Files

- **Video Clips**: Segments containing the interactions are saved in the `output_folder`.
- **Video File**: The File's name will includ details of the detected interactions , including:
  - Interaction start and end frames
  - Duration (in seconds)
  - Involved pedestrian IDs
  - Distance measurements for each frame

Example entry in the output `details.txt` file:
```
Start_Frame,End_Frame,Duration(s),ID_Count,IDs,Positions,Distances
100,150,10.12,2,1 2,"Frame 100: 1 2 -> 3.45m | Frame 101: 1 2 -> 3.40m", "3.45, 3.40"
```

---

---

## ðŸ™‹ Contact

**Wenjie Chen**  
PhD Researcher, Urban Planning  
Loughborough University  
ðŸ“§ W.Chen2@lboro.ac.uk

---

### Conclusion

This pipeline allows efficient detection and analysis of pedestrian social interactions from video footage. By leveraging YOLOv7 for pedestrian detection and custom tracking algorithms, it enables the study of pedestrian behavior in urban environments, contributing to urban planning and vitality assessments.

---
```
